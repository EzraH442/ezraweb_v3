---
title: 'Building an "image locker" from the ground up'
date: "2023-11-26"
headline: 'For the past few months (since August), I''ve been slowly building an image "locker" where my family and I can store and share all of photos. Since some of us use Android and some of us use Apple, it makes it difficult to share images with each other. And this is how I did it.'
featuredImage: "/images/2023-11-26-outdoors.png"
---

## Background information

For context, at this point I have developed a fairly robust system for building and deploying the things that I write. It will be useful for me to explain how this sysetm works so that it will be easy to follow along with what I've been doing.

#### 1. Oracle cloud

The first piece of the puzzle is [Oracle Cloud](https://www.oracle.com/ca-en/cloud/). I've been using their very generous free tier for over a year now, and am super thankful that my projects have been able to find a home in two of their beefy VMs.

#### 2. Porkbun and Cloudflare

I buy my domain name from [Porkbun](https://porkbun.com). I used to use namecheap, but switched to Porkbun from a friend's recomendation and have been happier using it ever since (cheaper and less scammy). I have my site registed with Cloudflare and have the DNS configured use it to route my main domain and auxillary subdomains to my servers in Oracle Cloud.

#### 4. Docker, Nginx, Certbot, and Jenkins

Inside my Oracle Cloud VMs, I run [Docker](https://www.docker.com/), nginx (as a docker container), certbot (also as a docker container), and [Jenkins](https://www.jenkins.io/)[guess what, also as a docker container](https://www.jenkins.io/doc/book/installing/docker/). By using nginx as a reverse-proxy for all my projects that run inside docker containers, I can provide SSL to all of them with certificates from LetsEncrypt generated by Certbot. I also run Jenkins to watch my GitHub repositories for changes and build docker containers whenever new commits are made in the main branch. What is convenient about this is that I can handle all this configuration in a portable monolithic docker-compose file. For ex.

```yml
# /docker-compose.yml
version: "3"
services:
  nginx:
    image: nginx:latest
    ports:
      - 80:80
      - 443:443
    logging:
      driver: syslog
      options:
        tag: "{{.ImageName}}/{{.Name}}/{{.ID}}"
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
      - ./data/nginx:/etc/nginx/conf.d
  certbot:
    image: certbot/certbot:latest
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt # notice that nginx and certbot share the same volumes to access cert files cenerated by cerbot
      - ./data/certbot/www:/var/www/certbot
  jenkins:
    build: ./jenkins
    user: root
    ports:
      - 8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/jenkins:/var/jenkins_home
  nextjs:
    image: ezraweb/nextjs:latest
  another-service:
    image: ezraweb/anotherimage:latest
  #{... other service...}
```

And my nginx configuration uses upstreams to forward request to various services:

```nginx
# /data/nginx/ezraweb.conf

upstream jenkins_upstream {
  server jenkins:8080;
}

upstream nextjs_upstream {
  server nextjs:3000;
}

upstream anotherservice_upstream {
  server anotherservie:port;
}

# { ... other upstreams ... }

server {
  listen 443 ssl;
  server_name jenkins.ezrahuang.com;
  server_tokens off;

  ssl_certificate     /etc/letsencrypt/live/ezrahuang.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/ezrahuang.com/privkey.pem;
  include             /etc/letsencrypt/options-ssl-nginx.conf;
  ssl_dhparam         /etc/letsencrypt/ssl-dhparams.pem;

  proxy_http_version 1.1;
  proxy_set_header Connection 'upgrade';
  proxy_set_header Upgrade $http_upgrade;

  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
  proxy_set_header X-Forwarded-Proto $scheme;
  proxy_cache_bypass $http_upgrade;

  location /.well-known/acme-challenge/ {
    root /var/www/certbot;
  }

  location / {
    proxy_pass http://jenkins_upstream;
  }
}

server {
  listen 80;
  server_name ezrahuang.com;
  server_tokens off;

  location /.well-known/acme-challenge/ {
      root /var/www/certbot;
  }

  location / {
    return 301 https://$host$request_uri;
  }
}

server {
  listen 443 ssl;
  server_name ezrahuang.com;
  server_tokens off;

  ssl_certificate     /etc/letsencrypt/live/ezrahuang.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/ezrahuang.com/privkey.pem;
  include             /etc/letsencrypt/options-ssl-nginx.conf;
  ssl_dhparam         /etc/letsencrypt/ssl-dhparams.pem;

  gzip on;
  gzip_proxied any;
  gzip_comp_level 4;
  gzip_types text/css application/javascript image/svg+xml;

  proxy_http_version 1.1;
  proxy_set_header Upgrade $http_upgrade;
  proxy_set_header Connection 'upgrade';
  proxy_pass_header Server;
  proxy_set_header Host $host;
  proxy_cache_bypass $http_upgrade;

  location /.well-known/acme-challenge/ {
      root /var/www/certbot;
  }

  location /wasm-test {
    proxy_pass http://wasm_upstream;
  }

  location /_next/static {
    proxy_cache STATIC;
    proxy_pass http://nextjs_upstream;
  }

  location /static {
    proxy_cache STATIC;
    proxy_ignore_headers Cache-Control;
    proxy_cache_valid 60m;
    proxy_pass http://nextjs_upstream;
  }

  location / {
    proxy_pass http://nextjs_upstream;
  }
}

# { ... server blocks for other subdomains ... }

```

Now in each one of my projects, I can declare a Dockerfile and Jenkinsfile with the following structure to build and deploy my projects

```dockerfile
# Dockerfile
FROM node:alpine
WORKDIR /usr/app

RUN npm install --global pm2
ARG SITEKEY
ARG POST_URL
ENV POST_URL=$POST_URL

COPY ./package.json ./
RUN npm install
COPY ./ ./
RUN SITEKEY=$SITEKEY POST_URL=$POST_URL npm run build

EXPOSE 3000

CMD [ "pm2-runtime", "npm", "--", "start" ]

```

```groovy
// Jenkinsfile
pipeline {
  agent any

  environment {
    SITEKEY  = credentials('ezraweb-nextjs-sitekey')
    POST_URL = credentials('ezraweb-nextjs-posturl')
  }

  stages {
    stage('build dev') {
      when { branch 'dev' }
      steps {
        sh 'docker build -t ezraweb/nextjs:dev --build-arg SITEKEY="${SITEKEY}" --build-arg POST_URL="${POST_URL}" .'
      }
    }
    stage('build main') {
      when { branch 'main' }
      steps {
        sh 'docker build -t ezraweb/nextjs:latest --build-arg SITEKEY="${SITEKEY}" --build-arg POST_URL="${POST_URL}" .'
      }
    }
  }
}

```

The handling of the generation of creation of dummy certificates (so nginx doesn't crash), requesting and verification of certificates (via certbot's webroot) can be automated in a bash script [adapted from this medium article](https://pentacent.medium.com/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71):

```bash
# init.sh

#!/bin/bash
domains=(ezrahuang.com www.ezrahuang.com jenkins.ezrahuang.com ...)
rsa_key_size=4096
data_path="./data/certbot"
email="ezrahuang155@gmail.com"
staging=0

if [ -d "$data_path" ]; then
  read -p "Existing data found for $domains. Continue and replace existing certificate? (y/N) " decision
  if [ "$decision" != "Y" ] && [ "$decision" != "y" ]; then
    exit
  fi
fi

rm -rf $data_path

if [ ! -e "$data_path/conf/options-ssl-nginx.conf" ] || [ ! -e "$data_path/conf/ssl-dhparams.pem" ]; then
  echo "### Downloading recommended TLS parameters ..."
  mkdir -p "$data_path/conf"
  curl -s https://raw.githubusercontent.com/certbot/certbot/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf > "$data_path/conf/options-ssl-nginx.conf"
  curl -s https://raw.githubusercontent.com/certbot/certbot/master/certbot/certbot/ssl-dhparams.pem > "$data_path/conf/ssl-dhparams.pem"
  echo
fi

echo "### Creating dummy certificate for $domains ..."
path="/etc/letsencrypt/live/$domains"
mkdir -p "$data_path/conf/live/$domains"
docker compose run --rm --entrypoint "\
  openssl req -x509 -nodes -newkey rsa:$rsa_key_size -days 1\
    -keyout '$path/privkey.pem' \
    -out '$path/fullchain.pem' \
    -subj '/CN=localhost'" certbot
echo

echo "### Starting upstream services ..."

echo "Starting nextjs"
docker compose up --force-recreate -d nextjs

echo "Starting wasm-server"
docker compose up --force-recreate -d wasm-server

echo "Starting jenkins"
docker compose up --force-recreate -d jenkins

# ... more of this, then


read -p "Press enter to continue"

echo "### Starting nginx ..."
docker compose up --force-recreate -d nginx

echo

echo "### Deleting dummy certificate for $domains ..."
docker compose run --rm --entrypoint "\
  rm -Rf /etc/letsencrypt/live/$domains && \
  rm -Rf /etc/letsencrypt/archive/$domains && \
  rm -Rf /etc/letsencrypt/renewal/$domains.conf" certbot
echo


echo "### Requesting Let's Encrypt certificate for $domains ..."
#Join $domains to -d args
domain_args=""
for domain in "${domains[@]}"; do
  domain_args="$domain_args -d $domain"
done

# Select appropriate email arg
case "$email" in
  "") email_arg="--register-unsafely-without-email" ;;
  *) email_arg="--email $email" ;;
esac

# Enable staging mode if needed
if [ $staging != "0" ]; then staging_arg="--staging"; fi

docker compose run --rm --entrypoint "\
  certbot certonly --webroot -w /var/www/certbot \
    $staging_arg \
    $email_arg \
    $domain_args \
    --rsa-key-size $rsa_key_size \
    --agree-tos \
    -v --debug-challenges \
    --force-renewal" certbot
echo

read -p "Press enter to continue (reload nginx)"

echo "### Reloading nginx ..."

docker compose up nginx --force-recreate -d

```

This combo has been very powerful and is what I've been using to host all my projects. Now with the hosting problem solved and all the internal plumbing exposed, we can get into the good stuff.

## The architecture

### 1. Backblaze

To store my images, I have decided to use [Backblaze](https://www.backblaze.com/). Not only is it cheaper than AWS S3, it provides and easy way for me to create a snapshot of all my files in case I want to export all the files I've stored. Moreover, they have an [alliance with Cloudflare](https://www.backblaze.com/blog/backblaze-and-cloudflare-partner-to-provide-free-data-transfer/) that allows me to access files with no data egress fees when they are accessed via a Cloudflare worker. Since I'm already using cloudflare to manage my DNS, I can deploy a simple web worker (again for free) that will fetch images for me from Backblaze. For all other Backblaze requests, I can use their S3 compatible API.

### 2. Cloudflare web worker

To access my files, I followed the [guide from Backblaze](https://www.backblaze.com/docs/cloud-storage-deliver-private-backblaze-b2-content-through-cloudflare-cdn) on how to deploy a web worker to serve private assets in Backblaze, with a cron job to refresh the Backblaze authorization token.

While getting free data egress from the Backblaze-Cloudflare alliance is nice, it provides an additional challenge to serve private assets. I only want authenticated family members to be able to access images, so how can I achieve this? It's not so simple.

### 3. The Authorization server

The goal will be to implement [the OAuth 2.0 flow](https://datatracker.ietf.org/doc/html/rfc6749#section-1.1) as described by the following image:
![The OAuth 2.0 Flow](/images/2023-11-26-oauth.png)

For me, the "Resource Owner" is the end user (the web browser), the "Client" will be any application I want (ex. my photo locker), the "Authorization Server" is what I am about to build, and the "Resource server" is any server with protected resources (ex. The Cloudflare web worker that fetches images from Backblaze). The "Authorization Grant" will be in the form of a username and password protected by a captcha token (to prevent brute force attacks).

Then, as a docker service, I can build an authorization server with the following endpoints:

- POST /auth - takes in a username, password, and a captcha token, and returns a JWT or some error messages
- POST /verify - verifies a JWT, returning whether or not the token is valid, and/or any messages (like if it is expired)

Now on any of my web applications, I can create a form protected by a captcha. After completing the form, the form data is sent back to the application, which sends a request through the docker network to the authorization server. On success, since I am opting to do token-based authentication, this will be stored in a Secure HTTP-Only cookie. Later, if I create other web applications, I can also set the `Domain` attribute on the cookie to have it be sent on requests to my subdomains as well, but for now, I will not set this attribute so that the cookie will be specific to that specific application.

### 4. The NuxtJS Backend

Initially, I had built the backend as a seperate docker service, but this proved to be annoying and unnecesary. However, if the NuxtJS service ever becomes too monolithic, I can split the backend into another service.

In the nuxt backend, I can declare the following endpoints

- POST /login

Get the authorization grant (username, password, and captcha token) from the frontend and send it to the authentication server to obtain a JWT to login the user in by setting a cookie `nuxt setCookie(...)`

- GET /files/get

Fetch a file based on its name from the cloudflare web worker that fetches it from Backblaze

- GET /files/list

List files and directories from Backblaze

- POST /files/upload

Upload a file to Backblaze

All API routes in the /files will be protected by an authorization middleware that will verify the user's JWT cookie against the authentication backend (through docker's internal network)

Note: Instead of creating a backend route to get a file, I could have set the Domain property of the cookie to allow it to be send to requsts on all my subdomains, and change the cloudflare worker to verify the token via the authorization cookie instead of a query parameter.

## The NuxtJS (frontend)

While I had considered writing the application with React/NextJS. I decided I wanted to try something new. After brief experiments with SolidJS/solid-start, svelte/svelte-kit, and Vue/NuxtJS, I setelled on using NuxtJS just because it had the most developed ecosystem.

## Summary

I like to visualize this combination (roughly) with the following image:

![architecture](/images/2023-11-26-arch.svg)

## What's next?

There are a few more things I would like to add to improve 2 aspects of my application: security and the user experience:

1. CSRF protection by adding and checking custom CSRF headers [as described by OSWAP](https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#custom-request-headers)
2. Implement refresh tokens on the authorization server to make it so that your login doesn't expire while using the app
3. Automatic conversion of HEIC files to PNG
4. Parallelize uploads for faster upload speed
5. Support uploading of a zip file with photos
6. Add functionality to download all files in a folder (and/or all directories recursively)
